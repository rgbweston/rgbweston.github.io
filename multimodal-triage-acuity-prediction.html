<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Meta Tags -->
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <!-- SEO Meta Tags -->
  <title>Multimodal Triage Acuity Prediction — Rohan Barrowcliff</title>
  <meta name="description" content="Development of a multimodal deep learning system for predicting emergency department triage acuity using structured clinical data and free-text chief complaints.">
  <meta name="keywords" content="triage prediction, emergency department, multimodal deep learning, MPNet, CNN, MIMIC-ED, ESI, acuity prediction, healthcare AI">
  <meta name="author" content="Rohan Barrowcliff">
  <meta name="robots" content="index, follow">
  <link rel="canonical" href="https://rgbweston.github.io/multimodal-triage-acuity-prediction.html">

  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:url" content="https://rgbweston.github.io/multimodal-triage-acuity-prediction.html">
  <meta property="og:title" content="Multimodal Triage Acuity Prediction">
  <meta property="og:description" content="Development of a multimodal deep learning system combining clinical data and text.">
  <meta property="og:image" content="https://rgbweston.github.io/assets/images/multimodal_CNN.svg">

  <!-- Favicon -->
  <link rel="icon" href="assets/images/favicon.ico" type="image/x-icon">
  <link rel="shortcut icon" href="assets/images/favicon.ico" type="image/x-icon">

  <!-- Stylesheet -->
  <link rel="stylesheet" href="assets/css/main.css">

  <!-- Google Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-14QPLF39JS"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-14QPLF39JS');
  </script>

  <!-- Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Article",
    "headline": "Multimodal Deep Learning for Emergency Department Triage Acuity Prediction",
    "author": {
      "@type": "Person",
      "name": "Rohan Barrowcliff"
    },
    "description": "Development of a multimodal deep learning system combining structured clinical data and free-text for triage acuity prediction.",
    "image": "https://rgbweston.github.io/assets/images/multimodal_CNN.svg"
  }
  </script>

  <style>
    .article-content {
      max-width: 900px;
      margin: 0 auto;
    }
    .article-content img {
      width: 100%;
      max-width: 700px;
      height: auto;
      border-radius: 8px;
      margin: 2rem auto;
      display: block;
      border: 1px solid var(--border-color);
    }
    .article-content p {
      margin-bottom: 1.5rem;
      font-size: 1.05rem;
      line-height: 1.8;
    }
    .metrics-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 1.5rem;
      margin: 2rem 0;
    }
    .metric-card {
      background: var(--background-alt);
      padding: 1.5rem;
      border-radius: 8px;
      text-align: center;
      border: 1px solid var(--border-color);
    }
    .metric-value {
      font-size: 2rem;
      font-weight: 700;
      color: var(--accent-color);
      margin-bottom: 0.5rem;
    }
    .metric-label {
      font-size: 0.9rem;
      color: var(--text-secondary);
    }
    .highlight-box {
      background: var(--background-alt);
      border-left: 4px solid var(--accent-color);
      padding: 1.5rem;
      margin: 2rem 0;
      border-radius: 4px;
    }
    .tech-stack {
      display: flex;
      flex-wrap: wrap;
      gap: 0.75rem;
      margin: 1.5rem 0;
    }
    .tech-tag {
      background: var(--accent-color);
      color: white;
      padding 0.5rem 1rem;
      border-radius: 20px;
      font-size: 0.9rem;
      font-weight: 500;
    }
  </style>
</head>
<body>

  <!-- Header -->
  <header class="site-header">
    <nav class="container nav-wrapper">
      <a href="index.html" class="site-logo">Rohan Barrowcliff</a>
      <ul class="nav-menu">
        <li><a href="index.html">Home</a></li>
        <li><a href="projects.html" class="active">Projects</a></li>
        <li><a href="about.html">About</a></li>
        <li><a href="services.html">Services</a></li>
        <li><a href="contact.html">Contact</a></li>
      </ul>
    </nav>
  </header>

  <main>
    <article class="section">
      <div class="container article-content">

        <h1 style="text-align: center; margin-bottom: 1rem;">Multimodal Deep Learning for Emergency Department Triage Acuity Prediction</h1>
        <p style="text-align: center; color: var(--text-secondary); margin-bottom: 3rem;">
          Combining structured clinical data and free-text chief complaints to predict patient triage acuity levels
        </p>

        <img src="assets/images/multimodal_CNN.svg" alt="Multimodal CNN Architecture combining text and structured clinical data">

        <h2>Project Overview</h2>
        <p>
          Emergency department triage is a critical process that determines the order and urgency with which patients receive care. The Emergency Severity Index (ESI) categorizes patients from Level 1 (most severe, life-threatening) to Level 5 (least severe). This project developed a multimodal deep learning system to predict triage acuity levels by combining traditional structured clinical data (vital signs, demographics) with free-text chief complaints processed through advanced natural language understanding.
        </p>

        <img src="assets/images/triage_overview.png" alt="High-level overview of the multimodal triage acuity prediction system">

        <div class="highlight-box">
          <p style="margin-bottom: 0;"><strong>Challenge:</strong> Traditional triage prediction models rely solely on structured data, missing the rich contextual information contained in patient chief complaints. This project aimed to build a multimodal system that effectively fuses numerical clinical features with semantic embeddings from text to improve prediction accuracy.</p>
        </div>

        <h2>The Journey: From Data to Deployment</h2>

        <h3>Phase 1: Understanding the Problem</h3>
        <p>
          My journey began with studying the MIMIC-IV-ED dataset from PhysioNet—a comprehensive collection of emergency department visits containing structured clinical measurements alongside free-text chief complaints. I quickly realized that vital signs alone tell only part of the story. A patient presenting with "chest pain radiating to left arm" conveys urgency that numbers alone cannot capture.
        </p>

        <p>
          The Emergency Severity Index presents a challenging multi-class classification problem with inherent class imbalance (ESI Level 1 patients are thankfully rare). I needed an approach that could handle both modalities effectively while maintaining clinical interpretability.
        </p>

        <h3>Phase 2: Building the Text Understanding Pipeline</h3>
        <p>
          The first major technical decision was choosing a text encoder. After researching biomedical NLP models, I selected <strong>all-MPNet-base-v2</strong> from sentence-transformers. While not specifically trained on medical text like BioBERT or ClinicalBERT, MPNet offers strong general semantic understanding and produces high-quality sentence embeddings (768 dimensions).
        </p>

        <p>
          I implemented batch processing for embedding generation to handle the dataset efficiently. The preprocessing pipeline:
        </p>
        <ul style="margin-left: 2rem; color: var(--text-secondary); line-height: 2;">
          <li>Tokenizes chief complaint text with padding and truncation (max 512 tokens)</li>
          <li>Generates contextualized embeddings using MPNet's transformer architecture</li>
          <li>Applies mean pooling across token embeddings for sentence-level representation</li>
          <li>Caches embeddings to disk for faster subsequent training runs</li>
        </ul>

        <p>
          This approach transformed unstructured text like "difficulty breathing, fever for 3 days" into dense vector representations capturing semantic meaning and clinical context.
        </p>

        <h3>Phase 3: Architecting the Multimodal Network</h3>
        <p>
          The core innovation was designing a neural architecture that could effectively fuse text and structured features. I developed a <strong>dual-branch convolutional neural network</strong>:
        </p>

        <div style="background: var(--background-alt); padding: 1.5rem; border-radius: 8px; margin: 1.5rem 0;">
          <h4 style="margin-top: 0;">Text Branch (Convolutional Processing)</h4>
          <ul style="margin-left: 1.5rem; color: var(--text-secondary); line-height: 1.8;">
            <li><strong>Conv1D Layer 1:</strong> 1 → 64 channels, kernel size 5, extracts local patterns from embeddings</li>
            <li><strong>MaxPool:</strong> Reduces dimensionality, retains salient features</li>
            <li><strong>Conv1D Layer 2:</strong> 64 → 32 channels, deeper feature extraction</li>
            <li><strong>MaxPool:</strong> Further compression to 32 × 384 = 12,288 features</li>
            <li><strong>Flatten:</strong> Prepares for fusion with structured features</li>
          </ul>
        </div>

        <div style="background: var(--background-alt); padding: 1.5rem; border-radius: 8px; margin: 1.5rem 0;">
          <h4 style="margin-top: 0;">Structured Data Branch (Fully Connected)</h4>
          <ul style="margin-left: 1.5rem; color: var(--text-secondary); line-height: 1.8;">
            <li><strong>Linear Layer 1:</strong> Input features → 16 neurons with ReLU activation</li>
            <li><strong>Linear Layer 2:</strong> 16 → 16 neurons, further non-linear transformation</li>
            <li>Processes vital signs (temperature, heart rate, respiratory rate, O2 saturation, blood pressure, pain score)</li>
            <li>Incorporates demographic features (gender, arrival transport method)</li>
          </ul>
        </div>

        <div style="background: var(--background-alt); padding: 1.5rem; border-radius: 8px; margin: 1.5rem 0;">
          <h4 style="margin-top: 0;">Fusion & Classification</h4>
          <ul style="margin-left: 1.5rem; color: var(--text-secondary); line-height: 1.8;">
            <li><strong>Concatenation:</strong> Combines 12,288 text features + 16 structured features</li>
            <li><strong>Final Classifier:</strong> Linear layer mapping to 5-class output (ESI 1-5)</li>
            <li><strong>Training:</strong> Cross-entropy loss, Adam optimizer (lr=0.001), 5 epochs</li>
          </ul>
        </div>

        <h3>Phase 4: Docker and DevOps Infrastructure</h3>
        <p>
          A critical aspect of this project was ensuring reproducible deployment in a Trusted Research Environment (TRE). Working with sensitive healthcare data required containerization using Docker, which packages applications and their dependencies into isolated, portable containers. The TRE provided a secure Linux environment where the MIMIC-IV-ED dataset could be accessed without compromising patient confidentiality.
        </p>

        <p>
          The DevOps application lifecycle began with creating Docker images on my local machine using <code>requirements.txt</code> and <code>Dockerfile</code> specifications. These images were compressed into <code>.tar.gz</code> format and transferred securely into the TRE via the Airlock system. Within the TRE, images were loaded onto the local Docker registry and instantiated as running containers to execute Python scripts for exploratory data analysis, model training, and evaluation.
        </p>

        <img src="assets/images/triage_devops_lifecycle.png" alt="The DevOps application lifecycle showing Docker image creation, compression, secure transfer to TRE, and container execution">

        <p>
          Command-line scripting (bash) was essential for managing working directories, running scripts, and launching successive Docker container iterations (e.g., <code>docker load -i acuity_pred_image.tar</code>). Additionally, CUDA commands were crucial for accessing the TRE's GPU resources, both for initializing Docker containers with GPU access and assigning computationally intensive tasks like chief complaint embedding generation to the GPU during script execution.
        </p>

        <h3>Phase 5: Data Preprocessing Challenges</h3>
        <p>
          Real-world healthcare data is messy. I encountered several data quality issues that required careful handling:
        </p>

        <ul style="margin-left: 2rem; color: var(--text-secondary); line-height: 2;">
          <li><strong>Pain Score Validation:</strong> Filtered records to ensure pain scores were numeric and within 0-10 range</li>
          <li><strong>Acuity Bounds:</strong> Validated ESI scores fell within 1-5 (converting to 0-indexed for model training)</li>
          <li><strong>Missing Data:</strong> Dropped incomplete records to maintain data integrity</li>
          <li><strong>Feature Scaling:</strong> Applied StandardScaler to vital signs for numerical stability</li>
          <li><strong>Categorical Encoding:</strong> One-hot encoded arrival transport and gender features</li>
        </ul>

        <p>
          This preprocessing pipeline ensured clean, normalized inputs for both the text embeddings and structured features branches.
        </p>

        <h3>Phase 6: Training and Evaluation</h3>
        <p>
          Training employed stratified train-test splitting (80/20) to maintain class balance across severity levels. I used batch training (batch size 32) with GPU acceleration where available. The model converged within 5 epochs, balancing computational efficiency with learning capacity.
        </p>

        <p>
          For evaluation, I implemented comprehensive metrics:
        </p>
        <ul style="margin-left: 2rem; color: var(--text-secondary); line-height: 2;">
          <li><strong>Per-Class ROC-AUC:</strong> Evaluated discriminative ability for each acuity level separately</li>
          <li><strong>Micro-Average AUC:</strong> Overall model performance across all classes</li>
          <li><strong>Precision, Recall, F1-Score:</strong> Class-wise performance metrics</li>
        </ul>

        <h2>Results & Performance</h2>

        <p>
          The project successfully progressed through three key DevOps milestones, each representing a major advancement in deployment capability within the TRE. The first Docker container enabled successful exploratory data analysis (EDA) of the MIMIC-IV-ED dataset. The second container was adapted for the ML pipeline and included critical GPU initialization in the TRE, enabling accelerated model training. The third and final container supported the Streamlit application, integrating live text-embedding generation with the trained model weights to deliver real-time predictions.
        </p>

        <img src="assets/images/triage_devops_milestones.png" alt="DevOps milestones achieved showing three iterations of Docker containers, from initial EDA through ML pipeline development to final Streamlit deployment with live prediction capability">

        <p>
          This iterative DevOps cycle worked seamlessly with the agile methodology employed throughout the project, allowing the team to adapt to challenges during weekly sprints. Completion of these milestones underpinned the group's progression, ultimately enabling training and evaluation of four classification models: two for acuity prediction and two for hospital admission disposition.
        </p>

        <div class="metrics-grid">
          <div class="metric-card">
            <div class="metric-value">0.93</div>
            <div class="metric-label">ROC AUC (ESI Level 1)</div>
            <small style="color: var(--text-secondary); font-size: 0.8rem;">Most severe cases</small>
          </div>
          <div class="metric-card">
            <div class="metric-value">0.91</div>
            <div class="metric-label">ROC AUC (ESI Level 4)</div>
            <small style="color: var(--text-secondary); font-size: 0.8rem;">Less urgent cases</small>
          </div>
          <div class="metric-card">
            <div class="metric-value">0.83</div>
            <div class="metric-label">ROC AUC (ESI Level 2)</div>
            <small style="color: var(--text-secondary); font-size: 0.8rem;">Emergent cases</small>
          </div>
          <div class="metric-card">
            <div class="metric-value">0.93</div>
            <div class="metric-label">Micro-Average AUC</div>
            <small style="color: var(--text-secondary); font-size: 0.8rem;">Overall performance</small>
          </div>
        </div>

        <img src="assets/images/triage_roc_auc.png" alt="MultiCNN-Acuity Model ROC-AUC curves for multi-class Emergency Severity Index (ESI) prediction, calculated using one-vs-rest approach with micro-average representing weighted average performance across all ESI classes">

        <h3>Key Findings</h3>
        <p>
          To compare and assess model performance, accuracy and F1 score metrics were prioritized. Accuracy is widely used both in research and in quantifying nurse triage performance, making it an appropriate benchmark. F1 score balances precision and recall, providing more informative evaluation under class imbalance conditions. The MultiCNN-Acuity model achieved an accuracy of 0.70 and F1 score of 0.68, improving upon emergency nurse accuracy (0.64) though not yet surpassing emergency physician performance (0.75).
        </p>
        <ul style="margin-left: 2rem; color: var(--text-secondary); line-height: 2;">
          <li><strong>Excellent ESI Level 1 Detection:</strong> The model achieved 0.93 AUC for the most critical patients, crucial for patient safety</li>
          <li><strong>Strong Overall Performance:</strong> 0.93 micro-average AUC demonstrates robust multi-class discrimination</li>
          <li><strong>Moderate Performance on ESI 2-3:</strong> Mid-acuity levels showed slightly lower AUC (0.79-0.83), likely due to clinical overlap between adjacent severity levels</li>
          <li><strong>Multimodal Advantage:</strong> Combining text and structured features outperformed either modality alone (based on ablation testing)</li>
        </ul>

        <div class="highlight-box">
          <p style="margin-bottom: 0;"><strong>Clinical Impact:</strong> The model demonstrates particular strength in identifying the most critical patients (ESI Level 1, AUC 0.93) and least urgent cases (ESI Levels 4-5, AUC 0.91-0.94), which is clinically valuable for triage prioritization. The slightly lower performance on mid-level acuity reflects the inherent difficulty even human clinicians face in distinguishing between adjacent ESI levels.</p>
        </div>

        <h2>Phase 7: Deployment with Streamlit</h2>

        <p>
          To make the model accessible for demonstration and potential clinical evaluation, I developed a Streamlit web application. The application's function was to mimic a clinician decision support tool and enable live prediction of acuity. This required integrating several critical components: (i) a custom Docker container with Streamlit dependencies; (ii) live text-embedding generation using the MPNet model; (iii) the complete ML pipeline including data preprocessing and trained model weights; and (iv) thoughtful user interface and experience (UI/UX) design considerations.
        </p>

        <p>
          From a UI/UX perspective, the interface was designed to balance simplicity, usability, and safety. Recognizing that such an application could potentially be regulated as a medical device due to its ability to guide clinical decisions, several safety features were incorporated. The app provides an intuitive interface for clinicians to:
        </p>
        <ul style="margin-left: 2rem; color: var(--text-secondary); line-height: 2;">
          <li>Input patient vital signs and demographics</li>
          <li>Enter free-text chief complaint</li>
          <li>Receive real-time acuity predictions with probability distributions across all ESI levels</li>
        </ul>

        <p>
          The deployment was containerized using Docker for reproducibility and secure operation within the TRE. This ensures the model can be evaluated in secure healthcare settings without exposing sensitive patient data.
        </p>

        <img src="assets/images/triage_streamlit.png" alt="Live acuity prediction using Streamlit application within the TRE, showing input fields for vital signs, arrival method, gender, and free-text chief complaint, with real-time Emergency Severity Index prediction and corresponding triage recommendations">

        <p>
          The final Streamlit interface accepts nine structured input variables from clinical triage assessment (temperature, heart rate, respiratory rate, oxygen saturation, blood pressure, pain score, arrival transport method, and gender) alongside the free-text chief complaint. The chief complaint is embedded in real-time using the same MPNet transformer employed during training. The application outputs a predicted ESI level (1 to 5) with appropriate action recommendations. Dual temperature units (Celsius and Fahrenheit) were included for flexibility, and a prominent notification informs users that this prediction is solely an AI-based recommendation and should not constitute a final clinical decision—supporting rather than replacing professional judgment.
        </p>

        <h2>Technical Architecture Summary</h2>

        <div class="tech-stack">
          <span class="tech-tag">PyTorch</span>
          <span class="tech-tag">MPNet</span>
          <span class="tech-tag">Sentence Transformers</span>
          <span class="tech-tag">Convolutional Neural Networks</span>
          <span class="tech-tag">MIMIC-IV-ED</span>
          <span class="tech-tag">Streamlit</span>
          <span class="tech-tag">Docker</span>
          <span class="tech-tag">scikit-learn</span>
        </div>

        <h2>Lessons Learned & Future Directions</h2>

        <p><strong>What Worked Well:</strong></p>
        <ul style="margin-left: 2rem; color: var(--text-secondary); line-height: 2;">
          <li>Convolutional processing of text embeddings captured local semantic patterns effectively</li>
          <li>Late fusion (after separate branch processing) allowed each modality to develop specialized representations</li>
          <li>Caching embeddings dramatically reduced iteration time during hyperparameter tuning</li>
          <li>Stratified splitting maintained class balance despite severity-level imbalance</li>
        </ul>

        <p><strong>Challenges & Limitations:</strong></p>
        <ul style="margin-left: 2rem; color: var(--text-secondary); line-height: 2;">
          <li><strong>Version Control:</strong> Multiple team members concurrently developing Python scripts for preprocessing and modeling, further modified for TRE compatibility and GPU optimization, led to conflicting file versions in the GitHub repository. This was mitigated by establishing a canonical <code>main</code> folder requiring pull requests approved by two group members and detailed changelog documentation</li>
          <li><strong>Class Imbalance:</strong> ESI Level 1 cases are rare; considered oversampling or class weighting in future iterations</li>
          <li><strong>Mid-Level Confusion:</strong> ESI 2-3 distinction remains challenging (AUC 0.79-0.83); clinical guidelines themselves show overlap between adjacent severity levels</li>
          <li><strong>Interpretability:</strong> Deep learning models lack transparency; future work could incorporate attention mechanisms to highlight influential chief complaint phrases</li>
          <li><strong>Generalizability:</strong> Model trained on MIMIC-ED (US academic hospital); external validation on UK population needed for NHS deployment</li>
        </ul>

        <p><strong>Future Enhancements:</strong></p>
        <ul style="margin-left: 2rem; color: var(--text-secondary); line-height: 2;">
          <li>Experiment with medical domain-specific language models such as Biomedical General Embedding (BGE-M3), which offers more powerful and clinically-oriented embeddings than the all-mpnet-base-v2 transformer used in this study. BGE-M3 likely provides superior clinical text clustering across diverse patient presentations</li>
          <li>Incorporate LLM-based ESI classification prediction (e.g., LLaMA3.1-70B), which has demonstrated remarkable 0.91 accuracy on similar tasks</li>
          <li>Implement feature rankings and attention mechanisms to boost clinician trust, uptake, and model interpretability</li>
          <li>Improve predictive performance in the moderate ESI range (levels 2-3) where clinical overlap presents the greatest challenge</li>
          <li>Conduct external validation studies to test generalizability to UK NHS patient populations</li>
          <li>Incorporate temporal features (time of day, day of week, seasonal patterns)</li>
          <li>Develop ensemble approaches combining multiple architectures</li>
          <li>Extend to predict additional outcomes (admission likelihood, length of stay)</li>
        </ul>

        <h2>Tools & Technologies</h2>
        <ul style="margin-left: 2rem; color: var(--text-secondary); line-height: 2;">
          <li><strong>PyTorch:</strong> Deep learning framework for model development and training</li>
          <li><strong>Sentence Transformers:</strong> MPNet embeddings for semantic text representation</li>
          <li><strong>MIMIC-IV-ED:</strong> Emergency department dataset from PhysioNet</li>
          <li><strong>scikit-learn:</strong> Preprocessing, metrics, train-test splitting</li>
          <li><strong>Streamlit:</strong> Interactive web application for model demonstration</li>
          <li><strong>Docker:</strong> Containerization for reproducible deployment in TREs</li>
          <li><strong>CUDA:</strong> GPU acceleration for training and inference</li>
        </ul>

        <h2>Significance & Impact</h2>
        <p>
          This project demonstrates that multimodal deep learning can effectively combine structured clinical data with unstructured text to predict emergency department triage acuity. In the context of NHS emergency departments where only 57% of patients now meet the 4-hour admission target (compared to 95% a decade ago), and with record 61,529 people waiting more than 12 hours in January 2025, automated triage support systems could help address the critical pressure on healthcare resources. Key contributions include:
        </p>
        <ul style="margin-left: 2rem; color: var(--text-secondary); line-height: 2;">
          <li><strong>Methodological:</strong> Demonstrated effective fusion of numerical and textual features using dual-branch CNN architecture with merged text CNN and structured data MLP</li>
          <li><strong>Clinical Relevance:</strong> Achieved accuracy (0.70) exceeding emergency nurses (0.64) and strong performance on critical patient identification (ESI Level 1 AUC 0.93), essential for patient safety</li>
          <li><strong>Reproducibility & Security:</strong> Provided complete containerized deployment pipeline enabling secure operation within Trusted Research Environments (TREs), ensuring patient data confidentiality while maintaining model accessibility</li>
          <li><strong>Translational Infrastructure:</strong> Successfully demonstrated the complete DevOps lifecycle from data preprocessing through GPU-accelerated training to live web application deployment, addressing the translation gap between ML research and clinical implementation</li>
          <li><strong>Educational Value:</strong> Serves as practical example of applied multimodal deep learning in healthcare, including agile methodology, version control, and team collaboration</li>
        </ul>

        <p>
          While not intended for immediate clinical deployment without extensive validation, this work provides a foundation for future triage decision support systems and demonstrates the value of integrating diverse data modalities in predictive healthcare models. The iterative DevOps approach successfully delivered a live decision support tool that respects legal, ethical, and technical constraints required for healthcare AI applications.
        </p>

        <div class="highlight-box">
          <p style="margin-bottom: 0;"><strong>Ethical Considerations:</strong> All development used the publicly available MIMIC-IV-ED demo dataset. Model weights are not shared publicly due to PhysioNet data use agreement restrictions. Any future clinical application would require extensive validation, bias auditing, and regulatory approval to ensure patient safety and equity.</p>
        </div>

        <div style="margin-top: 4rem; padding-top: 2rem; border-top: 1px solid var(--border-color);">
          <p><a href="https://github.com/rgbweston/MultiModal-Triage-Acuity-Prediction" target="_blank" rel="noopener noreferrer" class="read-more">View on GitHub</a></p>
          <p><a href="projects.html" class="read-more">Back to Projects</a></p>
        </div>

      </div>
    </article>
  </main>

  <!-- Footer -->
  <footer class="site-footer">
    <div class="container footer-content">
      <p class="copyright">© 2025 Rohan Barrowcliff | Data Science & Analytics</p>
      <ul class="footer-links">
        <li><a href="https://linkedin.com/in/rohanbarrowcliff" target="_blank" rel="noopener noreferrer">LinkedIn</a></li>
        <li><a href="https://github.com/rgbweston" target="_blank" rel="noopener noreferrer">GitHub</a></li>
        <li><a href="mailto:rgbweston@gmail.com">Email</a></li>
      </ul>
    </div>
  </footer>

</body>
</html>